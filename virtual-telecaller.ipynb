{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11288363,"sourceType":"datasetVersion","datasetId":7058175},{"sourceId":11403007,"sourceType":"datasetVersion","datasetId":7142293}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb\n%pip install -q google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:23:55.695093Z","iopub.execute_input":"2025-04-18T17:23:55.695325Z","iopub.status.idle":"2025-04-18T17:24:51.322220Z","shell.execute_reply.started":"2025-04-18T17:23:55.695301Z","shell.execute_reply":"2025-04-18T17:24:51.321292Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n)\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n)\nfrom datasets import load_dataset\nfrom trl import SFTTrainer\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n\nimport os, torch, wandb, io, bitsandbytes as bnb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:35:55.673502Z","iopub.execute_input":"2025-04-18T17:35:55.673844Z","iopub.status.idle":"2025-04-18T17:36:17.648970Z","shell.execute_reply.started":"2025-04-18T17:35:55.673813Z","shell.execute_reply":"2025-04-18T17:36:17.648125Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set up secrets and logins\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf_token\")\nwb_token = user_secrets.get_secret(\"wandb\")\nlogin(token=hf_token)\nwandb.login(key=wb_token)\nrun = wandb.init(project='Fine-tune Llama 3.2 on Customer Support Dataset', job_type=\"training\", anonymous=\"allow\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:36:54.656431Z","iopub.execute_input":"2025-04-18T17:36:54.656740Z","iopub.status.idle":"2025-04-18T17:37:07.717136Z","shell.execute_reply.started":"2025-04-18T17:36:54.656718Z","shell.execute_reply":"2025-04-18T17:37:07.716433Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnitichavda24\u001b[0m (\u001b[33mnitichavda24-nirma-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_173701-38kk545h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">comic-disco-39</a></strong> to <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Do NOT share these links with anyone. They can be used to claim your runs."},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Google Drive authentication\nSERVICE_ACCOUNT_FILE = '/kaggle/input/credential2/avid-influence-451503-v3-d8e2e9fce49c.json'  # Upload this file to Kaggle\nSCOPES = ['https://www.googleapis.com/auth/drive']\ncredentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\ndrive_service = build('drive', 'v3', credentials=credentials)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:37:13.148949Z","iopub.execute_input":"2025-04-18T17:37:13.149343Z","iopub.status.idle":"2025-04-18T17:37:13.219392Z","shell.execute_reply.started":"2025-04-18T17:37:13.149311Z","shell.execute_reply":"2025-04-18T17:37:13.218538Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def read_query_from_drive(file_id):\n    request = drive_service.files().get_media(fileId=file_id)\n    fh = io.BytesIO()\n    downloader = MediaIoBaseDownload(fh, request)\n    done = False\n    while not done:\n        status, done = downloader.next_chunk()\n    fh.seek(0)\n    return fh.read().decode()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:37:17.313027Z","iopub.execute_input":"2025-04-18T17:37:17.313340Z","iopub.status.idle":"2025-04-18T17:37:17.319015Z","shell.execute_reply.started":"2025-04-18T17:37:17.313304Z","shell.execute_reply":"2025-04-18T17:37:17.318069Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"base_model = \"meta-llama/Llama-3.2-3b-instruct\"\nnew_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\ndataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:37:19.446716Z","iopub.execute_input":"2025-04-18T17:37:19.447051Z","iopub.status.idle":"2025-04-18T17:37:19.451595Z","shell.execute_reply.started":"2025-04-18T17:37:19.447024Z","shell.execute_reply":"2025-04-18T17:37:19.450726Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\"\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:37:20.583251Z","iopub.execute_input":"2025-04-18T17:37:20.583594Z","iopub.status.idle":"2025-04-18T17:37:20.589569Z","shell.execute_reply.started":"2025-04-18T17:37:20.583563Z","shell.execute_reply":"2025-04-18T17:37:20.588770Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:37:22.489161Z","iopub.execute_input":"2025-04-18T17:37:22.489479Z","iopub.status.idle":"2025-04-18T17:38:02.463740Z","shell.execute_reply.started":"2025-04-18T17:37:22.489451Z","shell.execute_reply":"2025-04-18T17:38:02.463058Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97acc029384d4e6ab6db9ec6dcf0f29a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76c23d9f315429192e1289f6b10be4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c67de98d8e6f4de5b3106c3e2b73e4a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c687f4238dd4cd296bd4066ba66cdca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8902fd2f9f6f48e691143e18b5562e4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ef5a0de21e248c6a397081ef2a21ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"284bd0c02e1b44d4a622cec35fe554dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"571e53f8a3bb43acb3ea5b3242bef7bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfef6a1e984e45e9bd4d3f23bfabb63f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da02a3a310147cbbdce615968fb6207"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Dataset prep\ninstruction = \"\"\"You are a top-rated customer service agent named John. Be polite to customers and answer all their questions.\"\"\"\ndataset = load_dataset(dataset_name, split=\"train\")\ndataset = dataset.shuffle(seed=65).select(range(1000))\n\ndef format_chat_template(row):\n    row_json = [\n        {\"role\": \"system\", \"content\": instruction},\n        {\"role\": \"user\", \"content\": row[\"instruction\"]},\n        {\"role\": \"assistant\", \"content\": row[\"response\"]}\n    ]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(format_chat_template, num_proc=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:38:06.953212Z","iopub.execute_input":"2025-04-18T17:38:06.953521Z","iopub.status.idle":"2025-04-18T17:38:10.280221Z","shell.execute_reply.started":"2025-04-18T17:38:06.953482Z","shell.execute_reply":"2025-04-18T17:38:10.279224Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a80489fd7d3456fbd63f929598ae88d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(â€¦)t_Training_Dataset_27K_responses-v11.csv:   0%|          | 0.00/19.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ebb86c734e47f5841a3c15830e53db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/26872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d20b0a78a154d1d828a3a16eb6010ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31da6d6605794fd89c8faa578362751e"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# LoRA config\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)\n\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:38:14.130271Z","iopub.execute_input":"2025-04-18T17:38:14.130585Z","iopub.status.idle":"2025-04-18T17:38:14.138413Z","shell.execute_reply.started":"2025-04-18T17:38:14.130560Z","shell.execute_reply":"2025-04-18T17:38:14.137629Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = get_peft_model(model, peft_config)\ntokenizer.pad_token = tokenizer.eos_token\n\ntraining_arguments = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:38:16.429121Z","iopub.execute_input":"2025-04-18T17:38:16.429443Z","iopub.status.idle":"2025-04-18T17:38:17.073661Z","shell.execute_reply.started":"2025-04-18T17:38:16.429416Z","shell.execute_reply":"2025-04-18T17:38:17.072855Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    eval_dataset=dataset,\n    peft_config=peft_config,\n    processing_class=tokenizer,\n    args=training_arguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:38:19.699303Z","iopub.execute_input":"2025-04-18T17:38:19.699639Z","iopub.status.idle":"2025-04-18T17:38:21.419846Z","shell.execute_reply.started":"2025-04-18T17:38:19.699604Z","shell.execute_reply":"2025-04-18T17:38:21.418953Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b615c837766d424480822ae2554901fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8d50f98e8be4b7a93d48fdbb27d0ab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8ece3b9c8d242a19b17da0cb17792c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"febb353beb364aa098a995234596a1db"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:38:24.470993Z","iopub.execute_input":"2025-04-18T17:38:24.471318Z","iopub.status.idle":"2025-04-18T18:02:19.645447Z","shell.execute_reply.started":"2025-04-18T17:38:24.471287Z","shell.execute_reply":"2025-04-18T18:02:19.644804Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 23:52, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.748700</td>\n      <td>0.752964</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.527500</td>\n      <td>0.642907</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.603100</td>\n      <td>0.565690</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.441400</td>\n      <td>0.520692</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.424400</td>\n      <td>0.501356</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=0.7136747350692749, metrics={'train_runtime': 1434.4591, 'train_samples_per_second': 0.697, 'train_steps_per_second': 0.349, 'total_flos': 3328650423035904.0, 'train_loss': 0.7136747350692749})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:16:45.688193Z","iopub.execute_input":"2025-04-18T18:16:45.688549Z","iopub.status.idle":"2025-04-18T18:16:46.253920Z","shell.execute_reply.started":"2025-04-18T18:16:45.688519Z","shell.execute_reply":"2025-04-18T18:16:46.253220Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–…â–ƒâ–‚â–</td></tr><tr><td>eval/mean_token_accuracy</td><td>â–â–„â–†â–‡â–ˆ</td></tr><tr><td>eval/num_tokens</td><td>â–â–ƒâ–…â–†â–ˆ</td></tr><tr><td>eval/runtime</td><td>â–â–‡â–ˆâ–‚â–„</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‚â–â–‡â–…</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‚â–â–‡â–…</td></tr><tr><td>train/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–†â–…â–…â–…â–‚â–…â–ƒâ–ƒâ–…â–‚â–‚â–ƒâ–â–â–‚â–„â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–„â–â–â–…â–„â–ƒâ–…â–„â–ƒâ–„â–„â–„â–ƒ</td></tr><tr><td>train/learning_rate</td><td>â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–â–‚â–</td></tr><tr><td>train/mean_token_accuracy</td><td>â–â–‚â–„â–†â–†â–…â–†â–‡â–‡â–ˆâ–†â–‡â–†â–†â–‡â–†â–…â–‡â–…â–‡â–†â–‡â–†â–†â–†â–ˆâ–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–ˆ</td></tr><tr><td>train/num_tokens</td><td>â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.50136</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.84222</td></tr><tr><td>eval/num_tokens</td><td>195133</td></tr><tr><td>eval/runtime</td><td>196.3901</td></tr><tr><td>eval/samples_per_second</td><td>5.092</td></tr><tr><td>eval/steps_per_second</td><td>5.092</td></tr><tr><td>total_flos</td><td>3328650423035904.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>500</td></tr><tr><td>train/grad_norm</td><td>0.9579</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4244</td></tr><tr><td>train/mean_token_accuracy</td><td>0.86694</td></tr><tr><td>train/num_tokens</td><td>195133</td></tr><tr><td>train_loss</td><td>0.71367</td></tr><tr><td>train_runtime</td><td>1434.4591</td></tr><tr><td>train_samples_per_second</td><td>0.697</td></tr><tr><td>train_steps_per_second</td><td>0.349</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">comic-disco-39</strong> at: <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a><br> View project at: <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_173701-38kk545h/logs</code>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from google.colab import auth\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaIoBaseDownload\nimport io","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:42:42.426198Z","iopub.execute_input":"2025-04-18T18:42:42.426542Z","iopub.status.idle":"2025-04-18T18:42:42.430490Z","shell.execute_reply.started":"2025-04-18T18:42:42.426518Z","shell.execute_reply":"2025-04-18T18:42:42.429540Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Inference from query.txt and save response\nquery_file_id = \"1h6H4XiYDCGtEzK2RQMJrfQVVhxeUvUH-\"  # ğŸ” Replace with your actual file ID from Google Drive\nquery_text = read_query_from_drive(query_file_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:42:44.510710Z","iopub.execute_input":"2025-04-18T18:42:44.511082Z","iopub.status.idle":"2025-04-18T18:42:44.965164Z","shell.execute_reply.started":"2025-04-18T18:42:44.511052Z","shell.execute_reply":"2025-04-18T18:42:44.964206Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"messages = [\n    {\"role\": \"system\", \"content\": instruction},\n    {\"role\": \"user\", \"content\": query_text}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:42:47.350266Z","iopub.execute_input":"2025-04-18T18:42:47.350561Z","iopub.status.idle":"2025-04-18T18:42:47.354363Z","shell.execute_reply.started":"2025-04-18T18:42:47.350537Z","shell.execute_reply":"2025-04-18T18:42:47.353545Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\noutputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:42:49.829489Z","iopub.execute_input":"2025-04-18T18:42:49.829805Z","iopub.status.idle":"2025-04-18T18:42:57.990380Z","shell.execute_reply.started":"2025-04-18T18:42:49.829780Z","shell.execute_reply":"2025-04-18T18:42:57.989700Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"print(\"Generated Response:\\n\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:43:00.085544Z","iopub.execute_input":"2025-04-18T18:43:00.085889Z","iopub.status.idle":"2025-04-18T18:43:00.090581Z","shell.execute_reply.started":"2025-04-18T18:43:00.085860Z","shell.execute_reply":"2025-04-18T18:43:00.089796Z"}},"outputs":[{"name":"stdout","text":"Generated Response:\n We offer a variety of payment options to cater to your needs. You can choose from credit/debit cards, PayPal, bank transfer, Apple Pay, and Google Wallet. Feel free to explore these options and select the one that suits you best. If you have any specific questions or need further assistance, please don't hesitate to let me know.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"def upload_response_to_drive(text, filename, folder_id=None):\n    file_metadata = {'name': filename}\n    if folder_id:\n        file_metadata['parents'] = [folder_id]  # â¬…ï¸ ensures upload goes into shared folder\n    media = MediaIoBaseUpload(io.BytesIO(text.encode()), mimetype='text/plain')\n    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n    print(f\"âœ… Uploaded! View: https://drive.google.com/file/d/{file.get('id')}/view\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:43:05.079563Z","iopub.execute_input":"2025-04-18T18:43:05.079890Z","iopub.status.idle":"2025-04-18T18:43:05.084460Z","shell.execute_reply.started":"2025-04-18T18:43:05.079864Z","shell.execute_reply":"2025-04-18T18:43:05.083551Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from googleapiclient.http import MediaIoBaseUpload\nimport io","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:43:07.176578Z","iopub.execute_input":"2025-04-18T18:43:07.176949Z","iopub.status.idle":"2025-04-18T18:43:07.180850Z","shell.execute_reply.started":"2025-04-18T18:43:07.176919Z","shell.execute_reply":"2025-04-18T18:43:07.179999Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"folder_id = \"1mYtpp5m_RDrD7CLk8BbWLXAX0WIjcYRa\"  # ğŸ” Replace with the one you copied\n\n# Uploading model output to Drive inside that folder\nupload_response_to_drive(response, \"response.txt\", folder_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:43:09.446517Z","iopub.execute_input":"2025-04-18T18:43:09.446877Z","iopub.status.idle":"2025-04-18T18:43:10.768962Z","shell.execute_reply.started":"2025-04-18T18:43:09.446847Z","shell.execute_reply":"2025-04-18T18:43:10.768140Z"}},"outputs":[{"name":"stdout","text":"âœ… Uploaded! View: https://drive.google.com/file/d/1JSePKiEYSXL1xw36KmdXjlFeEjbC4nr_/view\n","output_type":"stream"}],"execution_count":34}]}