{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:23:55.695325Z",
     "iopub.status.busy": "2025-04-18T17:23:55.695093Z",
     "iopub.status.idle": "2025-04-18T17:24:51.322220Z",
     "shell.execute_reply": "2025-04-18T17:24:51.321292Z",
     "shell.execute_reply.started": "2025-04-18T17:23:55.695301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Virtual TeleCaller\n",
    "\n",
    "%%capture\n",
    "%pip install -U transformers \n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes \n",
    "%pip install -U wandb\n",
    "%pip install -q google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:35:55.673844Z",
     "iopub.status.busy": "2025-04-18T17:35:55.673502Z",
     "iopub.status.idle": "2025-04-18T17:36:17.648970Z",
     "shell.execute_reply": "2025-04-18T17:36:17.648125Z",
     "shell.execute_reply.started": "2025-04-18T17:35:55.673813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
    "\n",
    "import os, torch, wandb, io, bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:36:54.656740Z",
     "iopub.status.busy": "2025-04-18T17:36:54.656431Z",
     "iopub.status.idle": "2025-04-18T17:37:07.717136Z",
     "shell.execute_reply": "2025-04-18T17:37:07.716433Z",
     "shell.execute_reply.started": "2025-04-18T17:36:54.656718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnitichavda24\u001b[0m (\u001b[33mnitichavda24-nirma-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_173701-38kk545h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">comic-disco-39</a></strong> to <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up secrets and logins\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"hf_token\")\n",
    "wb_token = user_secrets.get_secret(\"wandb\")\n",
    "login(token=hf_token)\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(project='Fine-tune Llama 3.2 on Customer Support Dataset', job_type=\"training\", anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:37:13.149343Z",
     "iopub.status.busy": "2025-04-18T17:37:13.148949Z",
     "iopub.status.idle": "2025-04-18T17:37:13.219392Z",
     "shell.execute_reply": "2025-04-18T17:37:13.218538Z",
     "shell.execute_reply.started": "2025-04-18T17:37:13.149311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Google Drive authentication\n",
    "SERVICE_ACCOUNT_FILE = '/kaggle/input/credential2/avid-influence-451503-v3-d8e2e9fce49c.json'  # Upload this file to Kaggle\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "drive_service = build('drive', 'v3', credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:37:17.313340Z",
     "iopub.status.busy": "2025-04-18T17:37:17.313027Z",
     "iopub.status.idle": "2025-04-18T17:37:17.319015Z",
     "shell.execute_reply": "2025-04-18T17:37:17.318069Z",
     "shell.execute_reply.started": "2025-04-18T17:37:17.313304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_query_from_drive(file_id):\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "    fh.seek(0)\n",
    "    return fh.read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:37:19.447051Z",
     "iopub.status.busy": "2025-04-18T17:37:19.446716Z",
     "iopub.status.idle": "2025-04-18T17:37:19.451595Z",
     "shell.execute_reply": "2025-04-18T17:37:19.450726Z",
     "shell.execute_reply.started": "2025-04-18T17:37:19.447024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-3b-instruct\"\n",
    "new_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\n",
    "dataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:37:20.583594Z",
     "iopub.status.busy": "2025-04-18T17:37:20.583251Z",
     "iopub.status.idle": "2025-04-18T17:37:20.589569Z",
     "shell.execute_reply": "2025-04-18T17:37:20.588770Z",
     "shell.execute_reply.started": "2025-04-18T17:37:20.583563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:37:22.489479Z",
     "iopub.status.busy": "2025-04-18T17:37:22.489161Z",
     "iopub.status.idle": "2025-04-18T17:38:02.463740Z",
     "shell.execute_reply": "2025-04-18T17:38:02.463058Z",
     "shell.execute_reply.started": "2025-04-18T17:37:22.489451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97acc029384d4e6ab6db9ec6dcf0f29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76c23d9f315429192e1289f6b10be4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67de98d8e6f4de5b3106c3e2b73e4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c687f4238dd4cd296bd4066ba66cdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8902fd2f9f6f48e691143e18b5562e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef5a0de21e248c6a397081ef2a21ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284bd0c02e1b44d4a622cec35fe554dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571e53f8a3bb43acb3ea5b3242bef7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfef6a1e984e45e9bd4d3f23bfabb63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da02a3a310147cbbdce615968fb6207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:38:06.953521Z",
     "iopub.status.busy": "2025-04-18T17:38:06.953212Z",
     "iopub.status.idle": "2025-04-18T17:38:10.280221Z",
     "shell.execute_reply": "2025-04-18T17:38:10.279224Z",
     "shell.execute_reply.started": "2025-04-18T17:38:06.953482Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a80489fd7d3456fbd63f929598ae88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ebb86c734e47f5841a3c15830e53db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)t_Training_Dataset_27K_responses-v11.csv:   0%|          | 0.00/19.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d20b0a78a154d1d828a3a16eb6010ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/26872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31da6d6605794fd89c8faa578362751e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset prep\n",
    "instruction = \"\"\"You are a top-rated customer service agent named John. Be polite to customers and answer all their questions.\"\"\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset = dataset.shuffle(seed=65).select(range(1000))\n",
    "\n",
    "def format_chat_template(row):\n",
    "    row_json = [\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"response\"]}\n",
    "    ]\n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(format_chat_template, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:38:14.130585Z",
     "iopub.status.busy": "2025-04-18T17:38:14.130271Z",
     "iopub.status.idle": "2025-04-18T17:38:14.138413Z",
     "shell.execute_reply": "2025-04-18T17:38:14.137629Z",
     "shell.execute_reply.started": "2025-04-18T17:38:14.130560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:38:16.429443Z",
     "iopub.status.busy": "2025-04-18T17:38:16.429121Z",
     "iopub.status.idle": "2025-04-18T17:38:17.073661Z",
     "shell.execute_reply": "2025-04-18T17:38:17.072855Z",
     "shell.execute_reply.started": "2025-04-18T17:38:16.429416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:38:19.699639Z",
     "iopub.status.busy": "2025-04-18T17:38:19.699303Z",
     "iopub.status.idle": "2025-04-18T17:38:21.419846Z",
     "shell.execute_reply": "2025-04-18T17:38:21.418953Z",
     "shell.execute_reply.started": "2025-04-18T17:38:19.699604Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b615c837766d424480822ae2554901fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d50f98e8be4b7a93d48fdbb27d0ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ece3b9c8d242a19b17da0cb17792c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febb353beb364aa098a995234596a1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T17:38:24.471318Z",
     "iopub.status.busy": "2025-04-18T17:38:24.470993Z",
     "iopub.status.idle": "2025-04-18T18:02:19.645447Z",
     "shell.execute_reply": "2025-04-18T18:02:19.644804Z",
     "shell.execute_reply.started": "2025-04-18T17:38:24.471287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 23:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.752964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.527500</td>\n",
       "      <td>0.642907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.603100</td>\n",
       "      <td>0.565690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.441400</td>\n",
       "      <td>0.520692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>0.501356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.7136747350692749, metrics={'train_runtime': 1434.4591, 'train_samples_per_second': 0.697, 'train_steps_per_second': 0.349, 'total_flos': 3328650423035904.0, 'train_loss': 0.7136747350692749})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:16:45.688549Z",
     "iopub.status.busy": "2025-04-18T18:16:45.688193Z",
     "iopub.status.idle": "2025-04-18T18:16:46.253920Z",
     "shell.execute_reply": "2025-04-18T18:16:46.253220Z",
     "shell.execute_reply.started": "2025-04-18T18:16:45.688519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–…â–ƒâ–‚â–</td></tr><tr><td>eval/mean_token_accuracy</td><td>â–â–„â–†â–‡â–ˆ</td></tr><tr><td>eval/num_tokens</td><td>â–â–ƒâ–…â–†â–ˆ</td></tr><tr><td>eval/runtime</td><td>â–â–‡â–ˆâ–‚â–„</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‚â–â–‡â–…</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–‚â–â–‡â–…</td></tr><tr><td>train/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–†â–…â–…â–…â–‚â–…â–ƒâ–ƒâ–…â–‚â–‚â–ƒâ–â–â–‚â–„â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–„â–â–â–…â–„â–ƒâ–…â–„â–ƒâ–„â–„â–„â–ƒ</td></tr><tr><td>train/learning_rate</td><td>â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–â–‚â–</td></tr><tr><td>train/mean_token_accuracy</td><td>â–â–‚â–„â–†â–†â–…â–†â–‡â–‡â–ˆâ–†â–‡â–†â–†â–‡â–†â–…â–‡â–…â–‡â–†â–‡â–†â–†â–†â–ˆâ–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–ˆ</td></tr><tr><td>train/num_tokens</td><td>â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.50136</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.84222</td></tr><tr><td>eval/num_tokens</td><td>195133</td></tr><tr><td>eval/runtime</td><td>196.3901</td></tr><tr><td>eval/samples_per_second</td><td>5.092</td></tr><tr><td>eval/steps_per_second</td><td>5.092</td></tr><tr><td>total_flos</td><td>3328650423035904.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>500</td></tr><tr><td>train/grad_norm</td><td>0.9579</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4244</td></tr><tr><td>train/mean_token_accuracy</td><td>0.86694</td></tr><tr><td>train/num_tokens</td><td>195133</td></tr><tr><td>train_loss</td><td>0.71367</td></tr><tr><td>train_runtime</td><td>1434.4591</td></tr><tr><td>train_samples_per_second</td><td>0.697</td></tr><tr><td>train_steps_per_second</td><td>0.349</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-disco-39</strong> at: <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/38kk545h?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a><br> View project at: <a href='https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f' target=\"_blank\">https://wandb.ai/nitichavda24-nirma-university/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=43cbf43dfd4268ef66149c7c7bf33a4b630e6c6f</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250418_173701-38kk545h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:42:42.426542Z",
     "iopub.status.busy": "2025-04-18T18:42:42.426198Z",
     "iopub.status.idle": "2025-04-18T18:42:42.430490Z",
     "shell.execute_reply": "2025-04-18T18:42:42.429540Z",
     "shell.execute_reply.started": "2025-04-18T18:42:42.426518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:42:44.511082Z",
     "iopub.status.busy": "2025-04-18T18:42:44.510710Z",
     "iopub.status.idle": "2025-04-18T18:42:44.965164Z",
     "shell.execute_reply": "2025-04-18T18:42:44.964206Z",
     "shell.execute_reply.started": "2025-04-18T18:42:44.511052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Inference from query.txt and save response\n",
    "query_file_id = \"1h6H4XiYDCGtEzK2RQMJrfQVVhxeUvUH-\"  # ğŸ” Replace with your actual file ID from Google Drive\n",
    "query_text = read_query_from_drive(query_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:42:47.350561Z",
     "iopub.status.busy": "2025-04-18T18:42:47.350266Z",
     "iopub.status.idle": "2025-04-18T18:42:47.354363Z",
     "shell.execute_reply": "2025-04-18T18:42:47.353545Z",
     "shell.execute_reply.started": "2025-04-18T18:42:47.350537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": query_text}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:42:49.829805Z",
     "iopub.status.busy": "2025-04-18T18:42:49.829489Z",
     "iopub.status.idle": "2025-04-18T18:42:57.990380Z",
     "shell.execute_reply": "2025-04-18T18:42:57.989700Z",
     "shell.execute_reply.started": "2025-04-18T18:42:49.829780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:43:00.085889Z",
     "iopub.status.busy": "2025-04-18T18:43:00.085544Z",
     "iopub.status.idle": "2025-04-18T18:43:00.090581Z",
     "shell.execute_reply": "2025-04-18T18:43:00.089796Z",
     "shell.execute_reply.started": "2025-04-18T18:43:00.085860Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:\n",
      " We offer a variety of payment options to cater to your needs. You can choose from credit/debit cards, PayPal, bank transfer, Apple Pay, and Google Wallet. Feel free to explore these options and select the one that suits you best. If you have any specific questions or need further assistance, please don't hesitate to let me know.\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:43:05.079890Z",
     "iopub.status.busy": "2025-04-18T18:43:05.079563Z",
     "iopub.status.idle": "2025-04-18T18:43:05.084460Z",
     "shell.execute_reply": "2025-04-18T18:43:05.083551Z",
     "shell.execute_reply.started": "2025-04-18T18:43:05.079864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def upload_response_to_drive(text, filename, folder_id=None):\n",
    "    file_metadata = {'name': filename}\n",
    "    if folder_id:\n",
    "        file_metadata['parents'] = [folder_id]  # â¬…ï¸ ensures upload goes into shared folder\n",
    "    media = MediaIoBaseUpload(io.BytesIO(text.encode()), mimetype='text/plain')\n",
    "    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    print(f\"âœ… Uploaded! View: https://drive.google.com/file/d/{file.get('id')}/view\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:43:07.176949Z",
     "iopub.status.busy": "2025-04-18T18:43:07.176578Z",
     "iopub.status.idle": "2025-04-18T18:43:07.180850Z",
     "shell.execute_reply": "2025-04-18T18:43:07.179999Z",
     "shell.execute_reply.started": "2025-04-18T18:43:07.176919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from googleapiclient.http import MediaIoBaseUpload\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:43:09.446877Z",
     "iopub.status.busy": "2025-04-18T18:43:09.446517Z",
     "iopub.status.idle": "2025-04-18T18:43:10.768962Z",
     "shell.execute_reply": "2025-04-18T18:43:10.768140Z",
     "shell.execute_reply.started": "2025-04-18T18:43:09.446847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Uploaded! View: https://drive.google.com/file/d/1JSePKiEYSXL1xw36KmdXjlFeEjbC4nr_/view\n"
     ]
    }
   ],
   "source": [
    "folder_id = \"1mYtpp5m_RDrD7CLk8BbWLXAX0WIjcYRa\"  # ğŸ” Replace with the one you copied\n",
    "\n",
    "# Uploading model output to Drive inside that folder\n",
    "upload_response_to_drive(response, \"response.txt\", folder_id)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7058175,
     "sourceId": 11288363,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7142293,
     "sourceId": 11403007,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
